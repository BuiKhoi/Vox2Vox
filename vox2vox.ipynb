{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nibabel as nib\n",
    "import glob\n",
    "import time\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sys import stdout\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpim\n",
    "import elasticdeform as ed\n",
    "from scipy.ndimage.interpolation import affine_transform\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import apply_affine_transform\n",
    "\n",
    "Nclasses = 4\n",
    "classes = np.arange(Nclasses)\n",
    "\n",
    "# images lists\n",
    "t1_list = sorted(glob.glob('/nobackup/data/marci30/*/*/*t1.nii'))\n",
    "t2_list = sorted(glob.glob('/nobackup/data/marci30/*/*/*t2.nii'))\n",
    "t1ce_list = sorted(glob.glob('/nobackup/data/marci30/*/*/*t1ce.nii'))\n",
    "flair_list = sorted(glob.glob('/nobackup/data/marci30/*/*/*flair.nii'))\n",
    "seg_list = sorted(glob.glob('/nobackup/data/marci30/*/*/*seg.nii'))\n",
    "\n",
    "idxTrain, idxValid, idxTest = np.load('idxTrain_cv5.npy'), np.load('idxValid_cv5.npy'), np.load('idxTest.npy')\n",
    "print('Training, validation and testing set have lenghts: {}, {} and {} respectively.'.format(len(idxTrain), len(idxValid), len(idxTest)))\n",
    "\n",
    "sets = {'train': [], 'valid': [], 'test': []}\n",
    "\n",
    "for i in idxTrain:\n",
    "    sets['train'].append([t1_list[i], t2_list[i], t1ce_list[i], flair_list[i], seg_list[i]])\n",
    "for i in idxValid:\n",
    "    sets['valid'].append([t1_list[i], t2_list[i], t1ce_list[i], flair_list[i], seg_list[i]])\n",
    "for i in idxTest:\n",
    "    sets['test'].append([t1_list[i], t2_list[i], t1ce_list[i], flair_list[i], seg_list[i]])\n",
    "    \n",
    "def load_img(img_files):\n",
    "    ''' Load one image and its target form file\n",
    "    '''\n",
    "    N = len(img_files)\n",
    "    # target\n",
    "    y = nib.load(img_files[N-1]).get_fdata(dtype='float32')\n",
    "    y = y[40:200,34:226,8:136]\n",
    "    y[y==4]=3\n",
    "      \n",
    "    X_norm = np.empty((240, 240, 155, 4))\n",
    "    for channel in range(N-1):\n",
    "        X = nib.load(img_files[channel]).get_fdata(dtype='float32')\n",
    "        brain = X[X!=0] \n",
    "        brain_norm = np.zeros_like(X) # background at -100\n",
    "        norm = (brain - np.mean(brain))/np.std(brain)\n",
    "        brain_norm[X!=0] = norm\n",
    "        X_norm[:,:,:,channel] = brain_norm        \n",
    "        \n",
    "    X_norm = X_norm[40:200,34:226,8:136,:]    \n",
    "    del(X, brain, brain_norm)\n",
    "    \n",
    "    return X_norm, y\n",
    "\n",
    "def flip3D(X, y):\n",
    "    choice = np.random.randint(3)\n",
    "    if choice == 0: # flip on x\n",
    "        X_flip, y_flip = X[::-1, :, :, :], y[::-1, :, :]\n",
    "    if choice == 1: # flip on y\n",
    "        X_flip, y_flip = X[:, ::-1, :, :], y[:, ::-1, :]\n",
    "    if choice == 2: # flip on z\n",
    "        X_flip, y_flip = X[:, :, ::-1, :], y[:, :, ::-1]\n",
    "        \n",
    "    return X_flip, y_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import affine_transform\n",
    "\n",
    "def rotation3D(X, y):\n",
    "    alpha, beta, gamma = np.random.randint(0, 31, size=3)/180*np.pi\n",
    "    Rx = np.array([[1, 0, 0],\n",
    "                   [0, np.cos(alpha), -np.sin(alpha)],\n",
    "                   [0, np.sin(alpha), np.cos(alpha)]])\n",
    "    \n",
    "    Ry = np.array([[np.cos(beta), 0, np.sin(beta)],\n",
    "                   [0, 1, 0],\n",
    "                   [-np.sin(beta), 0, np.cos(beta)]])\n",
    "    \n",
    "    Rz = np.array([[np.cos(gamma), -np.sin(gamma), 0],\n",
    "                   [np.sin(gamma), np.cos(gamma), 0],\n",
    "                   [0, 0, 1]])\n",
    "    \n",
    "    R = np.dot(np.dot(Rx, Ry), Rz)\n",
    "    \n",
    "    X_rot = np.empty_like(X)\n",
    "    for channel in range(X.shape[-1]):\n",
    "        X_rot[:,:,:,channel] = affine_transform(X[:,:,:,channel], R, offset=0, order=3, mode='constant')\n",
    "    y_rot = affine_transform(y, R, offset=0, order=0, mode='constant')\n",
    "    \n",
    "    return X_rot, y_rot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, batch_size=4, dim=(160,192,128), n_channels=4, n_classes=4, shuffle=True, augmentation=False, patch_size=64, n_patches=8):\n",
    "        'Initialization'\n",
    "        self.list_IDs = list_IDs\n",
    "        self.batch_size = batch_size\n",
    "        self.dim = dim\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.augmentation = augmentation\n",
    "        self.patch_size = patch_size\n",
    "        self.n_patches = n_patches\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.ceil(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data     \n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "        if self.augmentation == True:\n",
    "            X, y = self.__data_augmentation(X, y)\n",
    "        \n",
    "        if index == self.__len__()-1:\n",
    "            self.on_epoch_end()\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "  \n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size, *self.dim))\n",
    "\n",
    "        # Generate data\n",
    "        for i, IDs in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            X[i], y[i] = load_img(IDs)\n",
    "            \n",
    "        if self.augmentation == True:\n",
    "            return X.astype('float32'), y\n",
    "        else:\n",
    "            return X.astype('float32'), to_categorical(y, self.n_classes)\n",
    "\n",
    "    def __data_augmentation(self, X, Y):\n",
    "        x_aug = np.empty((self.batch_size*self.n_patches, self.patch_size, self.patch_size, self.patch_size, self.n_channels))\n",
    "        y_aug = np.empty((self.batch_size*self.n_patches, self.patch_size, self.patch_size, self.patch_size))\n",
    "#         print(X.shape, Y.shape)\n",
    "        i = 0\n",
    "        for b in range(self.batch_size):\n",
    "            for _ in range(self.n_patches):\n",
    "                x = np.random.randint(self.dim[0]-self.patch_size+1) \n",
    "                y = np.random.randint(self.dim[1]-self.patch_size+1)\n",
    "                z = np.random.randint(self.dim[2]-self.patch_size+1)\n",
    "                \n",
    "                im = X[b, x:x+self.patch_size, y:y+self.patch_size, z:z+self.patch_size, :]\n",
    "                gt = Y[b, x:x+self.patch_size, y:y+self.patch_size, z:z+self.patch_size]\n",
    "                \n",
    "                aug_choice = np.random.randint(4)\n",
    "                # flip\n",
    "                if aug_choice == 1:\n",
    "                    im, gt = flip3D(im, gt)\n",
    "                # rotation\n",
    "                if aug_choice == 2:\n",
    "                    im, gt = rotation3D(im, gt)\n",
    "                # flip + rotation\n",
    "                if aug_choice == 3:\n",
    "                    im, gt = flip3D(im, gt)\n",
    "                    im, gt = rotation3D(im, gt)\n",
    "                \n",
    "                x_aug[i], y_aug[i] = im, gt\n",
    "                i += 1\n",
    "                \n",
    "        return x_aug, to_categorical(y_aug, self.n_classes)\n",
    "\n",
    "train_gen = DataGenerator(sets['train'], augmentation=True, patch_size=128, n_patches=1)\n",
    "valid_gen = DataGenerator(sets['valid'], augmentation=True, patch_size=128, n_patches=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = np.load('class_weights2.npy').astype('float32')\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN: Vox2Vox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv3D, Conv3DTranspose, Dropout, ReLU, LeakyReLU, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "\n",
    "class vox2vox():\n",
    "    def __init__(self, img_shape, seg_shape, class_weights, Nfilter_start=64, depth=4, batch_size=3, LAMBDA=5):\n",
    "        self.img_shape = img_shape\n",
    "        self.seg_shape = seg_shape\n",
    "        self.class_weights = class_weights\n",
    "        self.Nfilter_start = Nfilter_start\n",
    "        self.depth = depth\n",
    "        self.batch_size = batch_size\n",
    "        self.LAMBDA = LAMBDA\n",
    "        \n",
    "        def diceLoss(y_true, y_pred, w=self.class_weights):\n",
    "            y_true = tf.convert_to_tensor(y_true, 'float32')\n",
    "            y_pred = tf.convert_to_tensor(y_pred, y_true.dtype)\n",
    "\n",
    "            num = tf.math.reduce_sum(tf.math.multiply(w, tf.math.reduce_sum(tf.math.multiply(y_true, y_pred), axis=[0,1,2,3])))\n",
    "            den = tf.math.reduce_sum(tf.math.multiply(w, tf.math.reduce_sum(tf.math.add(y_true, y_pred), axis=[0,1,2,3])))+1e-5\n",
    "\n",
    "            return 1-2*num/den\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.Discriminator()\n",
    "        self.discriminator.compile(loss='mse', optimizer=Adam(2e-4, beta_1=0.5), metrics=['accuracy'])\n",
    "\n",
    "        # Construct Computational Graph of Generator\n",
    "        # Build the generator\n",
    "        self.generator = self.Generator()\n",
    "\n",
    "        # Input images and their conditioning images\n",
    "        seg = Input(shape=self.seg_shape)\n",
    "        img = Input(shape=self.img_shape)\n",
    "\n",
    "        # By conditioning on B generate a fake version of A\n",
    "        seg_pred = self.generator(img)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # Discriminators determines validity of translated images / condition pairs\n",
    "        valid = self.discriminator([seg_pred, img])\n",
    "\n",
    "        self.combined = Model(inputs=[seg, img], outputs=[valid, seg_pred])\n",
    "        self.combined.compile(loss=['mse', diceLoss], loss_weights=[1, self.LAMBDA], optimizer=Adam(2e-4, beta_1=0.5))\n",
    "    \n",
    "    def Generator(self):\n",
    "        '''\n",
    "        Generator model\n",
    "        '''\n",
    "\n",
    "        inputs = Input(self.img_shape, name='input_image')     \n",
    "\n",
    "        def encoder_step(layer, Nf, inorm=True):\n",
    "            x = Conv3D(Nf, kernel_size=4, strides=2, kernel_initializer='he_normal', padding='same')(layer)\n",
    "            if inorm:\n",
    "                x = InstanceNormalization()(x)\n",
    "            x = LeakyReLU()(x)\n",
    "            \n",
    "            return x\n",
    "        \n",
    "        def bottlenek(layer, Nf):\n",
    "            x = Conv3D(Nf, kernel_size=4, strides=2, kernel_initializer='he_normal', padding='same')(layer)\n",
    "            x = InstanceNormalization()(x)\n",
    "            x = LeakyReLU()(x)\n",
    "            for i in range(4):\n",
    "                y = Conv3D(Nf, kernel_size=4, strides=1, kernel_initializer='he_normal', padding='same')(x)\n",
    "                x = InstanceNormalization()(y)\n",
    "                x = Dropout(0.2)(x)\n",
    "                x = LeakyReLU()(x)\n",
    "                x = Concatenate()([x, y])\n",
    "                \n",
    "            return x\n",
    "\n",
    "        def decoder_step(layer, layer_to_concatenate, Nf):\n",
    "            x = Conv3DTranspose(Nf, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(layer)\n",
    "            x = InstanceNormalization()(x)\n",
    "            x = ReLU()(x)\n",
    "            x = Concatenate()([x, layer_to_concatenate])\n",
    "            return x\n",
    "\n",
    "        layers_to_concatenate = []\n",
    "        x = inputs\n",
    "\n",
    "        # encoder\n",
    "        for d in range(self.depth-1):\n",
    "            if d==0:\n",
    "                x = encoder_step(x, self.Nfilter_start*np.power(2,d), False)\n",
    "            else:\n",
    "                x = encoder_step(x, self.Nfilter_start*np.power(2,d))\n",
    "            layers_to_concatenate.append(x)\n",
    "        \n",
    "        # bottlenek\n",
    "        x = bottlenek(x, self.Nfilter_start*np.power(2,self.depth-1))\n",
    "\n",
    "        # decoder\n",
    "        for d in range(self.depth-2, -1, -1): \n",
    "            x = decoder_step(x, layers_to_concatenate.pop(), self.Nfilter_start*np.power(2,d))\n",
    "\n",
    "        # classifier\n",
    "        last = Conv3DTranspose(4, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal', activation='softmax', name='output_generator')(x)\n",
    "\n",
    "       # Create model\n",
    "        return Model(inputs=inputs, outputs=last, name='Generator')\n",
    "\n",
    "    def Discriminator(self):\n",
    "        '''\n",
    "        Discriminator model\n",
    "        '''\n",
    "        \n",
    "        inputs = Input(self.img_shape, name='input_image')\n",
    "        targets = Input(self.seg_shape, name='target_image')\n",
    "\n",
    "        def encoder_step(layer, Nf, inorm=True):\n",
    "            x = Conv3D(Nf, kernel_size=4, strides=2, kernel_initializer='he_normal', padding='same')(layer)\n",
    "            if inorm:\n",
    "                x = InstanceNormalization()(x)\n",
    "            x = LeakyReLU()(x)\n",
    "            return x\n",
    "\n",
    "        x = Concatenate()([inputs, targets])\n",
    "\n",
    "        for d in range(self.depth):\n",
    "            if d==0:\n",
    "                x = encoder_step(x, self.Nfilter_start*np.power(2,d), False)\n",
    "            else:\n",
    "                x = encoder_step(x, self.Nfilter_start*np.power(2,d))\n",
    "\n",
    "\n",
    "        last = tf.keras.layers.Conv3D(1, 4, strides=1, padding='same', kernel_initializer='he_normal', name='output_discriminator')(x) \n",
    "\n",
    "        return Model(inputs=[targets, inputs], outputs=last, name='Discriminator')\n",
    "    \n",
    "    def train_step(self, Xbatch, Ybatch, mp=True, n_workers=16):\n",
    "        # Generetor output\n",
    "        gen_output = self.generator.predict(Xbatch, use_multiprocessing=mp, workers=n_workers)\n",
    "        \n",
    "        # Discriminator output shape    \n",
    "        disc_output_shape = self.discriminator.output_shape\n",
    "        disc_output_shape = (gen_output.shape[0], *disc_output_shape[1:])\n",
    "        \n",
    "        # Train Discriminator\n",
    "        disc_loss_real = self.discriminator.fit([Ybatch, Xbatch], tf.ones(disc_output_shape), verbose=0, use_multiprocessing=mp, workers=n_workers)\n",
    "        disc_loss_fake = self.discriminator.fit([gen_output, Xbatch], tf.zeros(disc_output_shape), verbose=0, use_multiprocessing=mp, workers=n_workers)\n",
    "        #disc_loss = disc_loss_real['loss'][0] + disc_loss_fake['loss'][0]\n",
    "\n",
    "        # Train Generator\n",
    "        gen_loss = self.combined.fit([Ybatch, Xbatch], [tf.ones(disc_output_shape), Ybatch], verbose=0, use_multiprocessing=mp, workers=16)\n",
    "        #g_loss = [gen_loss.history['loss'][0], gen_loss.history['Discriminator_loss'][0], gen_loss.history['Generator_loss'][0]]\n",
    "        \n",
    "        return gen_loss\n",
    "    \n",
    "    def valid_step(self, Xbatch, Ybatch, mp=True, n_workers=16):\n",
    "        # Generetor output\n",
    "        gen_output = self.generator.predict(Xbatch, use_multiprocessing=mp, workers=n_workers)\n",
    "        \n",
    "        # Discriminator output shape    \n",
    "        disc_output_shape = self.discriminator.output_shape\n",
    "        disc_output_shape = (gen_output.shape[0], *disc_output_shape[1:])\n",
    "        \n",
    "        # Train Discriminator\n",
    "        disc_loss_real = self.discriminator.evaluate([Ybatch, Xbatch], tf.ones(disc_output_shape), verbose=0, use_multiprocessing=mp, workers=n_workers)\n",
    "        disc_loss_fake = self.discriminator.evaluate([gen_output, Xbatch], tf.zeros(disc_output_shape), verbose=0, use_multiprocessing=mp, workers=n_workers)\n",
    "        #disc_loss = disc_loss_real['loss'][0] + disc_loss_fake['loss'][0]\n",
    "\n",
    "        # Train Generator\n",
    "        gen_loss = self.combined.evaluate([Ybatch, Xbatch], [tf.ones(disc_output_shape), Ybatch], verbose=0, use_multiprocessing=mp, workers=n_workers)\n",
    "        #g_loss = [gen_loss.history['loss'][0], gen_loss.history['Discriminator_loss'][0], gen_loss.history['Generator_loss'][0]]\n",
    "        \n",
    "        return gen_loss\n",
    "\n",
    "    \n",
    "    def train(self, train_generator, valid_generator, nEpochs):\n",
    "        print('Training process:')\n",
    "        print('Training on {} and validating on {} batches.\\n'.format(len(train_generator), len(valid_generator)))\n",
    "        \n",
    "        # we save in a dictionary the histories obtained after each epoch\n",
    "        trends_train = tf.keras.callbacks.History()\n",
    "        trends_train.epoch = []\n",
    "        trends_train.history = {'loss': [], 'Discriminator_loss': [], 'Generator_loss': []}\n",
    "        \n",
    "        trends_valid = tf.keras.callbacks.History()\n",
    "        trends_valid.epoch = []\n",
    "        trends_valid.history = {'loss': [], 'Discriminator_loss': [], 'Generator_loss': []}\n",
    "        \n",
    "        path = '/home/marci30/Desktop/RESULTS/cv5' # './Results_mri2seg_128_aug_lambda{}'.format(self.LAMBDA)\n",
    "        if os.path.exists(path)==False:\n",
    "            os.mkdir(path)\n",
    "        \n",
    "        prev_loss = np.inf\n",
    "        \n",
    "        for e in range(nEpochs): \n",
    "            \n",
    "            print('Epoch {}/{}'.format(e+1,nEpochs))\n",
    "            start_time = time.time()           \n",
    "            \n",
    "            b = 0\n",
    "            for Xbatch, Ybatch in train_generator:\n",
    "                b+=1\n",
    "                gan_losses = self.train_step(Xbatch, Ybatch)\n",
    "                gan_losses.history['Generator_loss'][0] *= self.LAMBDA\n",
    "                stdout.write('\\rBatch: {}/{} - v2v_loss: {:.4f} - disc_loss: {:.4f} - gen_loss: {:.4f}'.format(b, len(train_generator), gan_losses.history['loss'][0], gan_losses.history['Discriminator_loss'][0], gan_losses.history['Generator_loss'][0]))\n",
    "                stdout.flush()\n",
    "            del(Xbatch, Ybatch)\n",
    "            \n",
    "            for Xbatch, Ybatch in valid_generator:\n",
    "                gan_losses_val = self.valid_step(Xbatch, Ybatch)   \n",
    "#             del(Xbatch, Ybatch)\n",
    "            \n",
    "            log = {'loss': gan_losses_val[0], 'Discriminator_loss': gan_losses_val[1], 'Generator_loss': gan_losses_val[2]*self.LAMBDA}\n",
    "            stdout.write(' - v2v_loss_val: {:.4f} - disc_loss_val: {:.4f} - gen_loss_val: {:.4f}'.format(gan_losses_val[0], gan_losses_val[1], gan_losses_val[2]))\n",
    "            elapsed_time = time.time() - start_time\n",
    "            stdout.write('\\nElapsed time: {}:{} mm:ss'.format(int(elapsed_time//60), int(elapsed_time%60)))\n",
    "            stdout.flush()\n",
    "                \n",
    "            # saving the loss values\n",
    "            trends_train.on_epoch_end(e, gan_losses.history)\n",
    "            trends_valid.on_epoch_end(e, log)        \n",
    "            print('\\n ')\n",
    "            \n",
    "            # save tmp images\n",
    "            y_pred = self.generator.predict(Xbatch)\n",
    "            Ybatch = np.argmax(Ybatch, axis=-1)\n",
    "            y_pred = np.argmax(y_pred, axis=-1)\n",
    "            \n",
    "            imsize, r, c = 128, 1, 3\n",
    "\n",
    "            canvas = np.zeros((r*imsize,c*imsize))\n",
    "            for i in range(r):\n",
    "                s = Xbatch[i,:,:,imsize//2,2] \n",
    "                canvas[i*imsize : (i+1)*imsize, 0 : imsize] = (s - np.min(s)) / (np.max(s)-np.min(s))\n",
    "                canvas[i*imsize : (i+1)*imsize, imsize : 2*imsize] = Ybatch[i,:,:,imsize//2]/6\n",
    "                canvas[i*imsize : (i+1)*imsize, 2*imsize : 3*imsize] = y_pred[i,:,:,imsize//2]/6\n",
    "\n",
    "            del(Xbatch, Ybatch)\n",
    "            \n",
    "            fname = (path + '/pred@epoch_{}.png').format(e+1)\n",
    "            mpim.imsave(fname, canvas, cmap='gray')\n",
    "            \n",
    "            if gan_losses_val[0]<prev_loss:\n",
    "                print(\"Validation loss decreaed from {:.4f} to {:.4f}. Hence models' weights are now saved.\".format(prev_loss, gan_losses_val[0]))\n",
    "                prev_loss = gan_losses_val[0]\n",
    "                self.generator.save_weights(path + '/Generator.h5') \n",
    "                self.discriminator.save_weights(path + '/Discriminator.h5') \n",
    "                self.combined.save_weights(path + '/Vox2Vox.h5')\n",
    "        \n",
    "        np.save(path + '/history_train', trends_train.history)\n",
    "        np.save(path + '/history_valid', trends_valid.history)\n",
    "        \n",
    "        return trends_train, trends_valid\n",
    "\n",
    "imShape = (128, 128, 128, 4) \n",
    "gtShape = (128, 128, 128, 4)\n",
    "gan = vox2vox(imShape, gtShape, class_weights, depth=4, batch_size=4, LAMBDA=5)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trends_train, trends_valid = gan.train(train_gen, valid_gen, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
