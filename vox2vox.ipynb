{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import nibabel as nib\n",
    "import glob\n",
    "import time\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sys import stdout\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpim\n",
    "import elasticdeform as ed\n",
    "from scipy.ndimage.interpolation import affine_transform\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training, validation and testing set have lenghts: 183, 45 and 57 respectively.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import apply_affine_transform\n",
    "\n",
    "Nclasses = 4\n",
    "classes = np.arange(Nclasses)\n",
    "\n",
    "# images lists\n",
    "t1_list = sorted(glob.glob('/nobackup/data/marci30/*/*/*t1.nii'))\n",
    "t2_list = sorted(glob.glob('/nobackup/data/marci30/*/*/*t2.nii'))\n",
    "t1ce_list = sorted(glob.glob('/nobackup/data/marci30/*/*/*t1ce.nii'))\n",
    "flair_list = sorted(glob.glob('/nobackup/data/marci30/*/*/*flair.nii'))\n",
    "seg_list = sorted(glob.glob('/nobackup/data/marci30/*/*/*seg.nii'))\n",
    "\n",
    "idxTrain, idxValid, idxTest = np.load('idxTrain_cv5.npy'), np.load('idxValid_cv5.npy'), np.load('idxTest.npy')\n",
    "print('Training, validation and testing set have lenghts: {}, {} and {} respectively.'.format(len(idxTrain), len(idxValid), len(idxTest)))\n",
    "\n",
    "sets = {'train': [], 'valid': [], 'test': []}\n",
    "\n",
    "for i in idxTrain:\n",
    "    sets['train'].append([t1_list[i], t2_list[i], t1ce_list[i], flair_list[i], seg_list[i]])\n",
    "for i in idxValid:\n",
    "    sets['valid'].append([t1_list[i], t2_list[i], t1ce_list[i], flair_list[i], seg_list[i]])\n",
    "for i in idxTest:\n",
    "    sets['test'].append([t1_list[i], t2_list[i], t1ce_list[i], flair_list[i], seg_list[i]])\n",
    "    \n",
    "def load_img(img_files):\n",
    "    ''' Load one image and its target form file\n",
    "    '''\n",
    "    N = len(img_files)\n",
    "    # target\n",
    "    y = nib.load(img_files[N-1]).get_fdata(dtype='float32')\n",
    "    y = y[40:200,34:226,8:136]\n",
    "    y[y==4]=3\n",
    "      \n",
    "    X_norm = np.empty((240, 240, 155, 4))\n",
    "    for channel in range(N-1):\n",
    "        X = nib.load(img_files[channel]).get_fdata(dtype='float32')\n",
    "        brain = X[X!=0] \n",
    "        brain_norm = np.zeros_like(X) # background at -100\n",
    "        norm = (brain - np.mean(brain))/np.std(brain)\n",
    "        brain_norm[X!=0] = norm\n",
    "        X_norm[:,:,:,channel] = brain_norm        \n",
    "        \n",
    "    X_norm = X_norm[40:200,34:226,8:136,:]    \n",
    "    del(X, brain, brain_norm)\n",
    "    \n",
    "    return X_norm, y\n",
    "\n",
    "def flip3D(X, y):\n",
    "    choice = np.random.randint(3)\n",
    "    if choice == 0: # flip on x\n",
    "        X_flip, y_flip = X[::-1, :, :, :], y[::-1, :, :]\n",
    "    if choice == 1: # flip on y\n",
    "        X_flip, y_flip = X[:, ::-1, :, :], y[:, ::-1, :]\n",
    "    if choice == 2: # flip on z\n",
    "        X_flip, y_flip = X[:, :, ::-1, :], y[:, :, ::-1]\n",
    "        \n",
    "    return X_flip, y_flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import affine_transform\n",
    "\n",
    "def rotation3D(X, y):\n",
    "    alpha, beta, gamma = np.random.randint(0, 31, size=3)/180*np.pi\n",
    "    Rx = np.array([[1, 0, 0],\n",
    "                   [0, np.cos(alpha), -np.sin(alpha)],\n",
    "                   [0, np.sin(alpha), np.cos(alpha)]])\n",
    "    \n",
    "    Ry = np.array([[np.cos(beta), 0, np.sin(beta)],\n",
    "                   [0, 1, 0],\n",
    "                   [-np.sin(beta), 0, np.cos(beta)]])\n",
    "    \n",
    "    Rz = np.array([[np.cos(gamma), -np.sin(gamma), 0],\n",
    "                   [np.sin(gamma), np.cos(gamma), 0],\n",
    "                   [0, 0, 1]])\n",
    "    \n",
    "    R = np.dot(np.dot(Rx, Ry), Rz)\n",
    "    \n",
    "    X_rot = np.empty_like(X)\n",
    "    for channel in range(X.shape[-1]):\n",
    "        X_rot[:,:,:,channel] = affine_transform(X[:,:,:,channel], R, offset=0, order=3, mode='constant')\n",
    "    y_rot = affine_transform(y, R, offset=0, order=0, mode='constant')\n",
    "    \n",
    "    return X_rot, y_rot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    'Generates data for Keras'\n",
    "    def __init__(self, list_IDs, batch_size=4, dim=(160,192,128), n_channels=4, n_classes=4, shuffle=True, augmentation=False, patch_size=64, n_patches=8):\n",
    "        'Initialization'\n",
    "        self.list_IDs = list_IDs\n",
    "        self.batch_size = batch_size\n",
    "        self.dim = dim\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.augmentation = augmentation\n",
    "        self.patch_size = patch_size\n",
    "        self.n_patches = n_patches\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.ceil(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "\n",
    "        # Generate data     \n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "        if self.augmentation == True:\n",
    "            X, y = self.__data_augmentation(X, y)\n",
    "        \n",
    "        if index == self.__len__()-1:\n",
    "            self.on_epoch_end()\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "  \n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        y = np.empty((self.batch_size, *self.dim))\n",
    "\n",
    "        # Generate data\n",
    "        for i, IDs in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            X[i], y[i] = load_img(IDs)\n",
    "            \n",
    "        if self.augmentation == True:\n",
    "            return X.astype('float32'), y\n",
    "        else:\n",
    "            return X.astype('float32'), to_categorical(y, self.n_classes)\n",
    "\n",
    "    def __data_augmentation(self, X, Y):\n",
    "        x_aug = np.empty((self.batch_size*self.n_patches, self.patch_size, self.patch_size, self.patch_size, self.n_channels))\n",
    "        y_aug = np.empty((self.batch_size*self.n_patches, self.patch_size, self.patch_size, self.patch_size))\n",
    "#         print(X.shape, Y.shape)\n",
    "        i = 0\n",
    "        for b in range(self.batch_size):\n",
    "            for _ in range(self.n_patches):\n",
    "                x = np.random.randint(self.dim[0]-self.patch_size+1) \n",
    "                y = np.random.randint(self.dim[1]-self.patch_size+1)\n",
    "                z = np.random.randint(self.dim[2]-self.patch_size+1)\n",
    "                \n",
    "                im = X[b, x:x+self.patch_size, y:y+self.patch_size, z:z+self.patch_size, :]\n",
    "                gt = Y[b, x:x+self.patch_size, y:y+self.patch_size, z:z+self.patch_size]\n",
    "                \n",
    "                aug_choice = np.random.randint(4)\n",
    "                # flip\n",
    "                if aug_choice == 1:\n",
    "                    im, gt = flip3D(im, gt)\n",
    "                # rotation\n",
    "                if aug_choice == 2:\n",
    "                    im, gt = rotation3D(im, gt)\n",
    "                # flip + rotation\n",
    "                if aug_choice == 3:\n",
    "                    im, gt = flip3D(im, gt)\n",
    "                    im, gt = rotation3D(im, gt)\n",
    "                \n",
    "                x_aug[i], y_aug[i] = im, gt\n",
    "                i += 1\n",
    "                \n",
    "        return x_aug, to_categorical(y_aug, self.n_classes)\n",
    "\n",
    "train_gen = DataGenerator(sets['train'], augmentation=True, patch_size=128, n_patches=1)\n",
    "valid_gen = DataGenerator(sets['valid'], augmentation=True, patch_size=128, n_patches=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.25646058 59.627304   16.495895   42.784115  ]\n"
     ]
    }
   ],
   "source": [
    "class_weights = np.load('class_weights2.npy').astype('float32')\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN: Vox2Vox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv3D, Conv3DTranspose, Dropout, ReLU, LeakyReLU, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.layers import InstanceNormalization\n",
    "\n",
    "class vox2vox():\n",
    "    def __init__(self, img_shape, seg_shape, class_weights, Nfilter_start=64, depth=4, batch_size=3, LAMBDA=5):\n",
    "        self.img_shape = img_shape\n",
    "        self.seg_shape = seg_shape\n",
    "        self.class_weights = class_weights\n",
    "        self.Nfilter_start = Nfilter_start\n",
    "        self.depth = depth\n",
    "        self.batch_size = batch_size\n",
    "        self.LAMBDA = LAMBDA\n",
    "        \n",
    "        def diceLoss(y_true, y_pred, w=self.class_weights):\n",
    "            y_true = tf.convert_to_tensor(y_true, 'float32')\n",
    "            y_pred = tf.convert_to_tensor(y_pred, y_true.dtype)\n",
    "\n",
    "            num = tf.math.reduce_sum(tf.math.multiply(w, tf.math.reduce_sum(tf.math.multiply(y_true, y_pred), axis=[0,1,2,3])))\n",
    "            den = tf.math.reduce_sum(tf.math.multiply(w, tf.math.reduce_sum(tf.math.add(y_true, y_pred), axis=[0,1,2,3])))+1e-5\n",
    "\n",
    "            return 1-2*num/den\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.Discriminator()\n",
    "        self.discriminator.compile(loss='mse', optimizer=Adam(2e-4, beta_1=0.5), metrics=['accuracy'])\n",
    "\n",
    "        # Construct Computational Graph of Generator\n",
    "        # Build the generator\n",
    "        self.generator = self.Generator()\n",
    "\n",
    "        # Input images and their conditioning images\n",
    "        seg = Input(shape=self.seg_shape)\n",
    "        img = Input(shape=self.img_shape)\n",
    "\n",
    "        # By conditioning on B generate a fake version of A\n",
    "        seg_pred = self.generator(img)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # Discriminators determines validity of translated images / condition pairs\n",
    "        valid = self.discriminator([seg_pred, img])\n",
    "\n",
    "        self.combined = Model(inputs=[seg, img], outputs=[valid, seg_pred])\n",
    "        self.combined.compile(loss=['mse', diceLoss], loss_weights=[1, self.LAMBDA], optimizer=Adam(2e-4, beta_1=0.5))\n",
    "    \n",
    "    def Generator(self):\n",
    "        '''\n",
    "        Generator model\n",
    "        '''\n",
    "\n",
    "        inputs = Input(self.img_shape, name='input_image')     \n",
    "\n",
    "        def encoder_step(layer, Nf, inorm=True):\n",
    "            x = Conv3D(Nf, kernel_size=4, strides=2, kernel_initializer='he_normal', padding='same')(layer)\n",
    "            if inorm:\n",
    "                x = InstanceNormalization()(x)\n",
    "            x = LeakyReLU()(x)\n",
    "            \n",
    "            return x\n",
    "        \n",
    "        def bottlenek(layer, Nf):\n",
    "            x = Conv3D(Nf, kernel_size=4, strides=2, kernel_initializer='he_normal', padding='same')(layer)\n",
    "            x = InstanceNormalization()(x)\n",
    "            x = LeakyReLU()(x)\n",
    "            for i in range(4):\n",
    "                y = Conv3D(Nf, kernel_size=4, strides=1, kernel_initializer='he_normal', padding='same')(x)\n",
    "                x = InstanceNormalization()(y)\n",
    "                x = Dropout(0.2)(x)\n",
    "                x = LeakyReLU()(x)\n",
    "                x = Concatenate()([x, y])\n",
    "                \n",
    "            return x\n",
    "\n",
    "        def decoder_step(layer, layer_to_concatenate, Nf):\n",
    "            x = Conv3DTranspose(Nf, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal')(layer)\n",
    "            x = InstanceNormalization()(x)\n",
    "            x = ReLU()(x)\n",
    "            x = Concatenate()([x, layer_to_concatenate])\n",
    "            return x\n",
    "\n",
    "        layers_to_concatenate = []\n",
    "        x = inputs\n",
    "\n",
    "        # encoder\n",
    "        for d in range(self.depth-1):\n",
    "            if d==0:\n",
    "                x = encoder_step(x, self.Nfilter_start*np.power(2,d), False)\n",
    "            else:\n",
    "                x = encoder_step(x, self.Nfilter_start*np.power(2,d))\n",
    "            layers_to_concatenate.append(x)\n",
    "        \n",
    "        # bottlenek\n",
    "        x = bottlenek(x, self.Nfilter_start*np.power(2,self.depth-1))\n",
    "\n",
    "        # decoder\n",
    "        for d in range(self.depth-2, -1, -1): \n",
    "            x = decoder_step(x, layers_to_concatenate.pop(), self.Nfilter_start*np.power(2,d))\n",
    "\n",
    "        # classifier\n",
    "        last = Conv3DTranspose(4, kernel_size=4, strides=2, padding='same', kernel_initializer='he_normal', activation='softmax', name='output_generator')(x)\n",
    "\n",
    "       # Create model\n",
    "        return Model(inputs=inputs, outputs=last, name='Generator')\n",
    "\n",
    "    def Discriminator(self):\n",
    "        '''\n",
    "        Discriminator model\n",
    "        '''\n",
    "        \n",
    "        inputs = Input(self.img_shape, name='input_image')\n",
    "        targets = Input(self.seg_shape, name='target_image')\n",
    "\n",
    "        def encoder_step(layer, Nf, inorm=True):\n",
    "            x = Conv3D(Nf, kernel_size=4, strides=2, kernel_initializer='he_normal', padding='same')(layer)\n",
    "            if inorm:\n",
    "                x = InstanceNormalization()(x)\n",
    "            x = LeakyReLU()(x)\n",
    "            return x\n",
    "\n",
    "        x = Concatenate()([inputs, targets])\n",
    "\n",
    "        for d in range(self.depth):\n",
    "            if d==0:\n",
    "                x = encoder_step(x, self.Nfilter_start*np.power(2,d), False)\n",
    "            else:\n",
    "                x = encoder_step(x, self.Nfilter_start*np.power(2,d))\n",
    "\n",
    "\n",
    "        last = tf.keras.layers.Conv3D(1, 4, strides=1, padding='same', kernel_initializer='he_normal', name='output_discriminator')(x) \n",
    "\n",
    "        return Model(inputs=[targets, inputs], outputs=last, name='Discriminator')\n",
    "    \n",
    "    def train_step(self, Xbatch, Ybatch, mp=True, n_workers=16):\n",
    "        # Generetor output\n",
    "        gen_output = self.generator.predict(Xbatch, use_multiprocessing=mp, workers=n_workers)\n",
    "        \n",
    "        # Discriminator output shape    \n",
    "        disc_output_shape = self.discriminator.output_shape\n",
    "        disc_output_shape = (gen_output.shape[0], *disc_output_shape[1:])\n",
    "        \n",
    "        # Train Discriminator\n",
    "        disc_loss_real = self.discriminator.fit([Ybatch, Xbatch], tf.ones(disc_output_shape), verbose=0, use_multiprocessing=mp, workers=n_workers)\n",
    "        disc_loss_fake = self.discriminator.fit([gen_output, Xbatch], tf.zeros(disc_output_shape), verbose=0, use_multiprocessing=mp, workers=n_workers)\n",
    "        #disc_loss = disc_loss_real['loss'][0] + disc_loss_fake['loss'][0]\n",
    "\n",
    "        # Train Generator\n",
    "        gen_loss = self.combined.fit([Ybatch, Xbatch], [tf.ones(disc_output_shape), Ybatch], verbose=0, use_multiprocessing=mp, workers=16)\n",
    "        #g_loss = [gen_loss.history['loss'][0], gen_loss.history['Discriminator_loss'][0], gen_loss.history['Generator_loss'][0]]\n",
    "        \n",
    "        return gen_loss\n",
    "    \n",
    "    def valid_step(self, Xbatch, Ybatch, mp=True, n_workers=16):\n",
    "        # Generetor output\n",
    "        gen_output = self.generator.predict(Xbatch, use_multiprocessing=mp, workers=n_workers)\n",
    "        \n",
    "        # Discriminator output shape    \n",
    "        disc_output_shape = self.discriminator.output_shape\n",
    "        disc_output_shape = (gen_output.shape[0], *disc_output_shape[1:])\n",
    "        \n",
    "        # Train Discriminator\n",
    "        disc_loss_real = self.discriminator.evaluate([Ybatch, Xbatch], tf.ones(disc_output_shape), verbose=0, use_multiprocessing=mp, workers=n_workers)\n",
    "        disc_loss_fake = self.discriminator.evaluate([gen_output, Xbatch], tf.zeros(disc_output_shape), verbose=0, use_multiprocessing=mp, workers=n_workers)\n",
    "        #disc_loss = disc_loss_real['loss'][0] + disc_loss_fake['loss'][0]\n",
    "\n",
    "        # Train Generator\n",
    "        gen_loss = self.combined.evaluate([Ybatch, Xbatch], [tf.ones(disc_output_shape), Ybatch], verbose=0, use_multiprocessing=mp, workers=n_workers)\n",
    "        #g_loss = [gen_loss.history['loss'][0], gen_loss.history['Discriminator_loss'][0], gen_loss.history['Generator_loss'][0]]\n",
    "        \n",
    "        return gen_loss\n",
    "\n",
    "    \n",
    "    def train(self, train_generator, valid_generator, nEpochs):\n",
    "        print('Training process:')\n",
    "        print('Training on {} and validating on {} batches.\\n'.format(len(train_generator), len(valid_generator)))\n",
    "        \n",
    "        # we save in a dictionary the histories obtained after each epoch\n",
    "        trends_train = tf.keras.callbacks.History()\n",
    "        trends_train.epoch = []\n",
    "        trends_train.history = {'loss': [], 'Discriminator_loss': [], 'Generator_loss': []}\n",
    "        \n",
    "        trends_valid = tf.keras.callbacks.History()\n",
    "        trends_valid.epoch = []\n",
    "        trends_valid.history = {'loss': [], 'Discriminator_loss': [], 'Generator_loss': []}\n",
    "        \n",
    "        path = '/home/marci30/Desktop/RESULTS/cv5' # './Results_mri2seg_128_aug_lambda{}'.format(self.LAMBDA)\n",
    "        if os.path.exists(path)==False:\n",
    "            os.mkdir(path)\n",
    "        \n",
    "        prev_loss = np.inf\n",
    "        \n",
    "        for e in range(nEpochs): \n",
    "            \n",
    "            print('Epoch {}/{}'.format(e+1,nEpochs))\n",
    "            start_time = time.time()           \n",
    "            \n",
    "            b = 0\n",
    "            for Xbatch, Ybatch in train_generator:\n",
    "                b+=1\n",
    "                gan_losses = self.train_step(Xbatch, Ybatch)\n",
    "                gan_losses.history['Generator_loss'][0] *= self.LAMBDA\n",
    "                stdout.write('\\rBatch: {}/{} - v2v_loss: {:.4f} - disc_loss: {:.4f} - gen_loss: {:.4f}'.format(b, len(train_generator), gan_losses.history['loss'][0], gan_losses.history['Discriminator_loss'][0], gan_losses.history['Generator_loss'][0]))\n",
    "                stdout.flush()\n",
    "            del(Xbatch, Ybatch)\n",
    "            \n",
    "            for Xbatch, Ybatch in valid_generator:\n",
    "                gan_losses_val = self.valid_step(Xbatch, Ybatch)   \n",
    "#             del(Xbatch, Ybatch)\n",
    "            \n",
    "            log = {'loss': gan_losses_val[0], 'Discriminator_loss': gan_losses_val[1], 'Generator_loss': gan_losses_val[2]*self.LAMBDA}\n",
    "            stdout.write(' - v2v_loss_val: {:.4f} - disc_loss_val: {:.4f} - gen_loss_val: {:.4f}'.format(gan_losses_val[0], gan_losses_val[1], gan_losses_val[2]))\n",
    "            elapsed_time = time.time() - start_time\n",
    "            stdout.write('\\nElapsed time: {}:{} mm:ss'.format(int(elapsed_time//60), int(elapsed_time%60)))\n",
    "            stdout.flush()\n",
    "                \n",
    "            # saving the loss values\n",
    "            trends_train.on_epoch_end(e, gan_losses.history)\n",
    "            trends_valid.on_epoch_end(e, log)        \n",
    "            print('\\n ')\n",
    "            \n",
    "            # save tmp images\n",
    "            y_pred = self.generator.predict(Xbatch)\n",
    "            Ybatch = np.argmax(Ybatch, axis=-1)\n",
    "            y_pred = np.argmax(y_pred, axis=-1)\n",
    "            \n",
    "            imsize, r, c = 128, 1, 3\n",
    "\n",
    "            canvas = np.zeros((r*imsize,c*imsize))\n",
    "            for i in range(r):\n",
    "                s = Xbatch[i,:,:,imsize//2,2] \n",
    "                canvas[i*imsize : (i+1)*imsize, 0 : imsize] = (s - np.min(s)) / (np.max(s)-np.min(s))\n",
    "                canvas[i*imsize : (i+1)*imsize, imsize : 2*imsize] = Ybatch[i,:,:,imsize//2]/6\n",
    "                canvas[i*imsize : (i+1)*imsize, 2*imsize : 3*imsize] = y_pred[i,:,:,imsize//2]/6\n",
    "\n",
    "            del(Xbatch, Ybatch)\n",
    "            \n",
    "            fname = (path + '/pred@epoch_{}.png').format(e+1)\n",
    "            mpim.imsave(fname, canvas, cmap='gray')\n",
    "            \n",
    "            if gan_losses_val[0]<prev_loss:\n",
    "                print(\"Validation loss decreaed from {:.4f} to {:.4f}. Hence models' weights are now saved.\".format(prev_loss, gan_losses_val[0]))\n",
    "                prev_loss = gan_losses_val[0]\n",
    "                self.generator.save_weights(path + '/Generator.h5') \n",
    "                self.discriminator.save_weights(path + '/Discriminator.h5') \n",
    "                self.combined.save_weights(path + '/Vox2Vox.h5')\n",
    "        \n",
    "        np.save(path + '/history_train', trends_train.history)\n",
    "        np.save(path + '/history_valid', trends_valid.history)\n",
    "        \n",
    "        return trends_train, trends_valid\n",
    "\n",
    "imShape = (128, 128, 128, 4) \n",
    "gtShape = (128, 128, 128, 4)\n",
    "gan = vox2vox(imShape, gtShape, class_weights, depth=4, batch_size=4, LAMBDA=5)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training process:\n",
      "Training on 46 and validating on 12 batches.\n",
      "\n",
      "Epoch 1/200\n",
      "Batch: 46/46 - v2v_loss: 5.4232 - disc_loss: 1.7908 - gen_loss: 3.6324 - v2v_loss_val: 5.1821 - disc_loss_val: 0.8156 - gen_loss_val: 0.8733\n",
      "Elapsed time: 9:43 mm:ss\n",
      " \n",
      "Validation loss decreaed from inf to 5.1821. Hence models' weights are now saved.\n",
      "Epoch 2/200\n",
      "Batch: 46/46 - v2v_loss: 3.5484 - disc_loss: 0.9495 - gen_loss: 2.5989 - v2v_loss_val: 3.3479 - disc_loss_val: 1.1908 - gen_loss_val: 0.4314\n",
      "Elapsed time: 9:38 mm:ss\n",
      " \n",
      "Validation loss decreaed from 5.1821 to 3.3479. Hence models' weights are now saved.\n",
      "Epoch 3/200\n",
      "Batch: 46/46 - v2v_loss: 2.9703 - disc_loss: 0.8099 - gen_loss: 2.1604 - v2v_loss_val: 2.1644 - disc_loss_val: 0.8685 - gen_loss_val: 0.2592\n",
      "Elapsed time: 9:40 mm:ss\n",
      " \n",
      "Validation loss decreaed from 3.3479 to 2.1644. Hence models' weights are now saved.\n",
      "Epoch 4/200\n",
      "Batch: 46/46 - v2v_loss: 2.9948 - disc_loss: 1.0415 - gen_loss: 1.9533 - v2v_loss_val: 2.7812 - disc_loss_val: 0.9446 - gen_loss_val: 0.3673\n",
      "Elapsed time: 9:26 mm:ss\n",
      " \n",
      "Epoch 5/200\n",
      "Batch: 46/46 - v2v_loss: 3.3148 - disc_loss: 1.1363 - gen_loss: 2.1785 - v2v_loss_val: 2.4033 - disc_loss_val: 0.8555 - gen_loss_val: 0.3096\n",
      "Elapsed time: 8:54 mm:ss\n",
      " \n",
      "Epoch 6/200\n",
      "Batch: 46/46 - v2v_loss: 2.8238 - disc_loss: 1.3012 - gen_loss: 1.5226 - v2v_loss_val: 2.1176 - disc_loss_val: 1.0494 - gen_loss_val: 0.2136\n",
      "Elapsed time: 9:23 mm:ss\n",
      " \n",
      "Validation loss decreaed from 2.1644 to 2.1176. Hence models' weights are now saved.\n",
      "Epoch 7/200\n",
      "Batch: 46/46 - v2v_loss: 1.8590 - disc_loss: 0.6993 - gen_loss: 1.1597 - v2v_loss_val: 1.8282 - disc_loss_val: 0.7459 - gen_loss_val: 0.2165\n",
      "Elapsed time: 8:57 mm:ss\n",
      " \n",
      "Validation loss decreaed from 2.1176 to 1.8282. Hence models' weights are now saved.\n",
      "Epoch 8/200\n",
      "Batch: 46/46 - v2v_loss: 2.8437 - disc_loss: 0.8035 - gen_loss: 2.0402 - v2v_loss_val: 1.8329 - disc_loss_val: 0.6065 - gen_loss_val: 0.2453\n",
      "Elapsed time: 9:11 mm:ss\n",
      " \n",
      "Epoch 9/200\n",
      "Batch: 46/46 - v2v_loss: 2.6313 - disc_loss: 0.8385 - gen_loss: 1.7927 - v2v_loss_val: 1.3880 - disc_loss_val: 0.5496 - gen_loss_val: 0.1677\n",
      "Elapsed time: 9:19 mm:ss\n",
      " \n",
      "Validation loss decreaed from 1.8282 to 1.3880. Hence models' weights are now saved.\n",
      "Epoch 10/200\n",
      "Batch: 46/46 - v2v_loss: 1.5839 - disc_loss: 0.4347 - gen_loss: 1.1492 - v2v_loss_val: 0.8713 - disc_loss_val: 0.6009 - gen_loss_val: 0.0541\n",
      "Elapsed time: 9:27 mm:ss\n",
      " \n",
      "Validation loss decreaed from 1.3880 to 0.8713. Hence models' weights are now saved.\n",
      "Epoch 11/200\n",
      "Batch: 46/46 - v2v_loss: 1.5288 - disc_loss: 0.4943 - gen_loss: 1.0345 - v2v_loss_val: 1.6002 - disc_loss_val: 0.5751 - gen_loss_val: 0.2050\n",
      "Elapsed time: 9:3 mm:ss\n",
      " \n",
      "Epoch 12/200\n",
      "Batch: 46/46 - v2v_loss: 1.5043 - disc_loss: 0.4220 - gen_loss: 1.0823 - v2v_loss_val: 1.0378 - disc_loss_val: 0.5041 - gen_loss_val: 0.1067\n",
      "Elapsed time: 9:3 mm:ss\n",
      " \n",
      "Epoch 13/200\n",
      "Batch: 46/46 - v2v_loss: 1.6731 - disc_loss: 0.3989 - gen_loss: 1.2742 - v2v_loss_val: 1.2864 - disc_loss_val: 0.4481 - gen_loss_val: 0.1677\n",
      "Elapsed time: 9:28 mm:ss\n",
      " \n",
      "Epoch 14/200\n",
      "Batch: 46/46 - v2v_loss: 2.1084 - disc_loss: 0.3636 - gen_loss: 1.7448 - v2v_loss_val: 0.9637 - disc_loss_val: 0.3571 - gen_loss_val: 0.1213\n",
      "Elapsed time: 9:48 mm:ss\n",
      " \n",
      "Epoch 15/200\n",
      "Batch: 46/46 - v2v_loss: 1.4884 - disc_loss: 0.4404 - gen_loss: 1.0480 - v2v_loss_val: 1.0322 - disc_loss_val: 0.4564 - gen_loss_val: 0.1152\n",
      "Elapsed time: 8:52 mm:ss\n",
      " \n",
      "Epoch 16/200\n",
      "Batch: 46/46 - v2v_loss: 1.6390 - disc_loss: 0.3818 - gen_loss: 1.2572 - v2v_loss_val: 0.9728 - disc_loss_val: 0.3910 - gen_loss_val: 0.1164\n",
      "Elapsed time: 8:32 mm:ss\n",
      " \n",
      "Epoch 17/200\n",
      "Batch: 46/46 - v2v_loss: 1.4703 - disc_loss: 0.4214 - gen_loss: 1.0488 - v2v_loss_val: 1.1170 - disc_loss_val: 0.3833 - gen_loss_val: 0.1467\n",
      "Elapsed time: 9:19 mm:ss\n",
      " \n",
      "Epoch 18/200\n",
      "Batch: 46/46 - v2v_loss: 2.1560 - disc_loss: 0.4158 - gen_loss: 1.7402 - v2v_loss_val: 0.8900 - disc_loss_val: 0.4562 - gen_loss_val: 0.0867\n",
      "Elapsed time: 9:41 mm:ss\n",
      " \n",
      "Epoch 19/200\n",
      "Batch: 46/46 - v2v_loss: 1.8288 - disc_loss: 0.3832 - gen_loss: 1.4456 - v2v_loss_val: 1.7998 - disc_loss_val: 0.4282 - gen_loss_val: 0.2743\n",
      "Elapsed time: 9:25 mm:ss\n",
      " \n",
      "Epoch 20/200\n",
      "Batch: 46/46 - v2v_loss: 1.6745 - disc_loss: 0.3619 - gen_loss: 1.3126 - v2v_loss_val: 1.3142 - disc_loss_val: 0.3990 - gen_loss_val: 0.1830\n",
      "Elapsed time: 9:29 mm:ss\n",
      " \n",
      "Epoch 21/200\n",
      "Batch: 46/46 - v2v_loss: 1.0069 - disc_loss: 0.3532 - gen_loss: 0.6536 - v2v_loss_val: 1.1487 - disc_loss_val: 0.3374 - gen_loss_val: 0.1623\n",
      "Elapsed time: 9:23 mm:ss\n",
      " \n",
      "Epoch 22/200\n",
      "Batch: 46/46 - v2v_loss: 1.1973 - disc_loss: 0.3415 - gen_loss: 0.8558 - v2v_loss_val: 1.0982 - disc_loss_val: 0.3592 - gen_loss_val: 0.1478\n",
      "Elapsed time: 9:16 mm:ss\n",
      " \n",
      "Epoch 23/200\n",
      "Batch: 46/46 - v2v_loss: 1.8718 - disc_loss: 0.4249 - gen_loss: 1.4469 - v2v_loss_val: 1.2441 - disc_loss_val: 0.3835 - gen_loss_val: 0.1721\n",
      "Elapsed time: 8:40 mm:ss\n",
      " \n",
      "Epoch 24/200\n",
      "Batch: 46/46 - v2v_loss: 1.3775 - disc_loss: 0.3500 - gen_loss: 1.0275 - v2v_loss_val: 0.7791 - disc_loss_val: 0.3663 - gen_loss_val: 0.0826\n",
      "Elapsed time: 9:16 mm:ss\n",
      " \n",
      "Validation loss decreaed from 0.8713 to 0.7791. Hence models' weights are now saved.\n",
      "Epoch 25/200\n",
      "Batch: 46/46 - v2v_loss: 1.3871 - disc_loss: 0.3360 - gen_loss: 1.0511 - v2v_loss_val: 0.8203 - disc_loss_val: 0.3779 - gen_loss_val: 0.0885\n",
      "Elapsed time: 9:9 mm:ss\n",
      " \n",
      "Epoch 26/200\n",
      "Batch: 46/46 - v2v_loss: 1.2154 - disc_loss: 0.3453 - gen_loss: 0.8702 - v2v_loss_val: 1.1714 - disc_loss_val: 0.3884 - gen_loss_val: 0.1566\n",
      "Elapsed time: 8:34 mm:ss\n",
      " \n",
      "Epoch 27/200\n",
      "Batch: 46/46 - v2v_loss: 1.5643 - disc_loss: 0.4102 - gen_loss: 1.1541 - v2v_loss_val: 1.7758 - disc_loss_val: 0.4658 - gen_loss_val: 0.2620\n",
      "Elapsed time: 9:39 mm:ss\n",
      " \n",
      "Epoch 28/200\n",
      "Batch: 46/46 - v2v_loss: 1.5725 - disc_loss: 0.4267 - gen_loss: 1.1458 - v2v_loss_val: 0.8831 - disc_loss_val: 0.4946 - gen_loss_val: 0.0777\n",
      "Elapsed time: 9:22 mm:ss\n",
      " \n",
      "Epoch 29/200\n",
      "Batch: 46/46 - v2v_loss: 1.4708 - disc_loss: 0.3639 - gen_loss: 1.1068 - v2v_loss_val: 1.6640 - disc_loss_val: 0.3545 - gen_loss_val: 0.2619\n",
      "Elapsed time: 9:12 mm:ss\n",
      " \n",
      "Epoch 30/200\n",
      "Batch: 46/46 - v2v_loss: 1.3993 - disc_loss: 0.3740 - gen_loss: 1.0253 - v2v_loss_val: 3.1567 - disc_loss_val: 0.4245 - gen_loss_val: 0.5464\n",
      "Elapsed time: 9:19 mm:ss\n",
      " \n",
      "Epoch 31/200\n",
      "Batch: 46/46 - v2v_loss: 1.9893 - disc_loss: 0.4167 - gen_loss: 1.5727 - v2v_loss_val: 0.9064 - disc_loss_val: 0.4438 - gen_loss_val: 0.0925\n",
      "Elapsed time: 9:9 mm:ss\n",
      " \n",
      "Epoch 32/200\n",
      "Batch: 46/46 - v2v_loss: 0.7838 - disc_loss: 0.3513 - gen_loss: 0.4324 - v2v_loss_val: 0.9102 - disc_loss_val: 0.4101 - gen_loss_val: 0.1000\n",
      "Elapsed time: 8:55 mm:ss\n",
      " \n",
      "Epoch 33/200\n",
      "Batch: 46/46 - v2v_loss: 1.3338 - disc_loss: 0.3309 - gen_loss: 1.0029 - v2v_loss_val: 0.9027 - disc_loss_val: 0.3754 - gen_loss_val: 0.1055\n",
      "Elapsed time: 8:53 mm:ss\n",
      " \n",
      "Epoch 34/200\n",
      "Batch: 46/46 - v2v_loss: 1.2207 - disc_loss: 0.3720 - gen_loss: 0.8486 - v2v_loss_val: 1.2582 - disc_loss_val: 0.4262 - gen_loss_val: 0.1664\n",
      "Elapsed time: 9:15 mm:ss\n",
      " \n",
      "Epoch 35/200\n",
      "Batch: 46/46 - v2v_loss: 2.1241 - disc_loss: 0.3486 - gen_loss: 1.7756 - v2v_loss_val: 1.1898 - disc_loss_val: 0.3515 - gen_loss_val: 0.1677\n",
      "Elapsed time: 9:24 mm:ss\n",
      " \n",
      "Epoch 36/200\n",
      "Batch: 46/46 - v2v_loss: 1.0567 - disc_loss: 0.3632 - gen_loss: 0.6935 - v2v_loss_val: 0.8800 - disc_loss_val: 0.4109 - gen_loss_val: 0.0938\n",
      "Elapsed time: 9:14 mm:ss\n",
      " \n",
      "Epoch 37/200\n",
      "Batch: 46/46 - v2v_loss: 1.1548 - disc_loss: 0.4477 - gen_loss: 0.7071 - v2v_loss_val: 3.2381 - disc_loss_val: 0.5409 - gen_loss_val: 0.5394\n",
      "Elapsed time: 8:50 mm:ss\n",
      " \n",
      "Epoch 38/200\n",
      "Batch: 46/46 - v2v_loss: 0.9868 - disc_loss: 0.3291 - gen_loss: 0.6576 - v2v_loss_val: 0.8761 - disc_loss_val: 0.3544 - gen_loss_val: 0.1043\n",
      "Elapsed time: 8:55 mm:ss\n",
      " \n",
      "Epoch 39/200\n",
      "Batch: 46/46 - v2v_loss: 1.4826 - disc_loss: 0.3168 - gen_loss: 1.1658 - v2v_loss_val: 1.5082 - disc_loss_val: 0.3407 - gen_loss_val: 0.2335\n",
      "Elapsed time: 9:2 mm:ss\n",
      " \n",
      "Epoch 40/200\n",
      "Batch: 46/46 - v2v_loss: 1.8686 - disc_loss: 0.3294 - gen_loss: 1.5392 - v2v_loss_val: 3.0625 - disc_loss_val: 0.3575 - gen_loss_val: 0.5410\n",
      "Elapsed time: 8:58 mm:ss\n",
      " \n",
      "Epoch 41/200\n",
      "Batch: 46/46 - v2v_loss: 1.3335 - disc_loss: 0.3503 - gen_loss: 0.9832 - v2v_loss_val: 0.7824 - disc_loss_val: 0.4107 - gen_loss_val: 0.0743\n",
      "Elapsed time: 9:7 mm:ss\n",
      " \n",
      "Epoch 42/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 46/46 - v2v_loss: 1.6773 - disc_loss: 0.3444 - gen_loss: 1.3329 - v2v_loss_val: 0.5686 - disc_loss_val: 0.4220 - gen_loss_val: 0.0293\n",
      "Elapsed time: 9:17 mm:ss\n",
      " \n",
      "Validation loss decreaed from 0.7791 to 0.5686. Hence models' weights are now saved.\n",
      "Epoch 43/200\n",
      "Batch: 46/46 - v2v_loss: 1.8405 - disc_loss: 0.3901 - gen_loss: 1.4504 - v2v_loss_val: 0.9318 - disc_loss_val: 0.4414 - gen_loss_val: 0.0981\n",
      "Elapsed time: 8:58 mm:ss\n",
      " \n",
      "Epoch 44/200\n",
      "Batch: 46/46 - v2v_loss: 1.2591 - disc_loss: 0.3585 - gen_loss: 0.9006 - v2v_loss_val: 0.6713 - disc_loss_val: 0.4119 - gen_loss_val: 0.0519\n",
      "Elapsed time: 9:38 mm:ss\n",
      " \n",
      "Epoch 45/200\n",
      "Batch: 46/46 - v2v_loss: 1.3588 - disc_loss: 0.3605 - gen_loss: 0.9983 - v2v_loss_val: 0.7612 - disc_loss_val: 0.3784 - gen_loss_val: 0.0766\n",
      "Elapsed time: 9:20 mm:ss\n",
      " \n",
      "Epoch 46/200\n",
      "Batch: 46/46 - v2v_loss: 1.3081 - disc_loss: 0.6087 - gen_loss: 0.6994 - v2v_loss_val: 1.2826 - disc_loss_val: 0.7962 - gen_loss_val: 0.0973\n",
      "Elapsed time: 9:27 mm:ss\n",
      " \n",
      "Epoch 47/200\n",
      "Batch: 46/46 - v2v_loss: 1.4922 - disc_loss: 0.3652 - gen_loss: 1.1270 - v2v_loss_val: 0.7233 - disc_loss_val: 0.3932 - gen_loss_val: 0.0660\n",
      "Elapsed time: 8:45 mm:ss\n",
      " \n",
      "Epoch 48/200\n",
      "Batch: 46/46 - v2v_loss: 1.2768 - disc_loss: 0.3331 - gen_loss: 0.9438 - v2v_loss_val: 1.4198 - disc_loss_val: 0.3829 - gen_loss_val: 0.2074\n",
      "Elapsed time: 9:17 mm:ss\n",
      " \n",
      "Epoch 49/200\n",
      "Batch: 46/46 - v2v_loss: 1.4635 - disc_loss: 0.4614 - gen_loss: 1.0021 - v2v_loss_val: 0.9063 - disc_loss_val: 0.5794 - gen_loss_val: 0.0654\n",
      "Elapsed time: 8:59 mm:ss\n",
      " \n",
      "Epoch 50/200\n",
      "Batch: 46/46 - v2v_loss: 0.8282 - disc_loss: 0.3248 - gen_loss: 0.5034 - v2v_loss_val: 0.8034 - disc_loss_val: 0.3502 - gen_loss_val: 0.0906\n",
      "Elapsed time: 9:42 mm:ss\n",
      " \n",
      "Epoch 51/200\n",
      "Batch: 46/46 - v2v_loss: 1.0266 - disc_loss: 0.2996 - gen_loss: 0.7270 - v2v_loss_val: 1.2360 - disc_loss_val: 0.3858 - gen_loss_val: 0.1701\n",
      "Elapsed time: 9:26 mm:ss\n",
      " \n",
      "Epoch 52/200\n",
      "Batch: 46/46 - v2v_loss: 1.2742 - disc_loss: 0.3426 - gen_loss: 0.9317 - v2v_loss_val: 0.9858 - disc_loss_val: 0.3735 - gen_loss_val: 0.1225\n",
      "Elapsed time: 9:52 mm:ss\n",
      " \n",
      "Epoch 53/200\n",
      "Batch: 46/46 - v2v_loss: 1.0942 - disc_loss: 0.3257 - gen_loss: 0.7685 - v2v_loss_val: 0.8815 - disc_loss_val: 0.3043 - gen_loss_val: 0.1154\n",
      "Elapsed time: 9:20 mm:ss\n",
      " \n",
      "Epoch 54/200\n",
      "Batch: 46/46 - v2v_loss: 1.3388 - disc_loss: 0.3922 - gen_loss: 0.9466 - v2v_loss_val: 1.1151 - disc_loss_val: 0.4477 - gen_loss_val: 0.1335\n",
      "Elapsed time: 9:30 mm:ss\n",
      " \n",
      "Epoch 55/200\n",
      "Batch: 46/46 - v2v_loss: 1.1821 - disc_loss: 0.3824 - gen_loss: 0.7998 - v2v_loss_val: 1.0786 - disc_loss_val: 0.4577 - gen_loss_val: 0.1242\n",
      "Elapsed time: 9:44 mm:ss\n",
      " \n",
      "Epoch 56/200\n",
      "Batch: 46/46 - v2v_loss: 1.8177 - disc_loss: 0.3405 - gen_loss: 1.4772 - v2v_loss_val: 1.1216 - disc_loss_val: 0.3849 - gen_loss_val: 0.1473\n",
      "Elapsed time: 9:29 mm:ss\n",
      " \n",
      "Epoch 57/200\n",
      "Batch: 46/46 - v2v_loss: 0.8942 - disc_loss: 0.3112 - gen_loss: 0.5829 - v2v_loss_val: 3.0969 - disc_loss_val: 0.3583 - gen_loss_val: 0.5477\n",
      "Elapsed time: 9:37 mm:ss\n",
      " \n",
      "Epoch 58/200\n",
      "Batch: 46/46 - v2v_loss: 1.3761 - disc_loss: 0.3371 - gen_loss: 1.0391 - v2v_loss_val: 0.7933 - disc_loss_val: 0.3862 - gen_loss_val: 0.0814\n",
      "Elapsed time: 9:21 mm:ss\n",
      " \n",
      "Epoch 59/200\n",
      "Batch: 46/46 - v2v_loss: 1.2120 - disc_loss: 0.4100 - gen_loss: 0.8019 - v2v_loss_val: 0.8099 - disc_loss_val: 0.5652 - gen_loss_val: 0.0490\n",
      "Elapsed time: 9:49 mm:ss\n",
      " \n",
      "Epoch 60/200\n",
      "Batch: 46/46 - v2v_loss: 1.6374 - disc_loss: 0.4766 - gen_loss: 1.1608 - v2v_loss_val: 1.0627 - disc_loss_val: 0.6168 - gen_loss_val: 0.0892\n",
      "Elapsed time: 9:22 mm:ss\n",
      " \n",
      "Epoch 61/200\n",
      "Batch: 46/46 - v2v_loss: 0.7038 - disc_loss: 0.3301 - gen_loss: 0.3736 - v2v_loss_val: 0.9638 - disc_loss_val: 0.3900 - gen_loss_val: 0.1147\n",
      "Elapsed time: 9:11 mm:ss\n",
      " \n",
      "Epoch 62/200\n",
      "Batch: 46/46 - v2v_loss: 1.3146 - disc_loss: 0.4298 - gen_loss: 0.8847 - v2v_loss_val: 0.8755 - disc_loss_val: 0.5373 - gen_loss_val: 0.0676\n",
      "Elapsed time: 9:32 mm:ss\n",
      " \n",
      "Epoch 63/200\n",
      "Batch: 46/46 - v2v_loss: 0.8250 - disc_loss: 0.3055 - gen_loss: 0.5195 - v2v_loss_val: 1.0292 - disc_loss_val: 0.3879 - gen_loss_val: 0.1283\n",
      "Elapsed time: 9:16 mm:ss\n",
      " \n",
      "Epoch 64/200\n",
      "Batch: 46/46 - v2v_loss: 1.4514 - disc_loss: 0.3765 - gen_loss: 1.0750 - v2v_loss_val: 1.7340 - disc_loss_val: 0.4733 - gen_loss_val: 0.2522\n",
      "Elapsed time: 8:58 mm:ss\n",
      " \n",
      "Epoch 65/200\n",
      "Batch: 46/46 - v2v_loss: 1.1024 - disc_loss: 0.3345 - gen_loss: 0.7679 - v2v_loss_val: 0.7407 - disc_loss_val: 0.3705 - gen_loss_val: 0.0740\n",
      "Elapsed time: 9:27 mm:ss\n",
      " \n",
      "Epoch 66/200\n",
      "Batch: 46/46 - v2v_loss: 1.2203 - disc_loss: 0.3251 - gen_loss: 0.8952 - v2v_loss_val: 0.7010 - disc_loss_val: 0.3926 - gen_loss_val: 0.0617\n",
      "Elapsed time: 9:9 mm:ss\n",
      " \n",
      "Epoch 67/200\n",
      "Batch: 46/46 - v2v_loss: 1.1452 - disc_loss: 0.3678 - gen_loss: 0.7774 - v2v_loss_val: 1.7276 - disc_loss_val: 0.4531 - gen_loss_val: 0.2549\n",
      "Elapsed time: 8:58 mm:ss\n",
      " \n",
      "Epoch 68/200\n",
      "Batch: 46/46 - v2v_loss: 1.2781 - disc_loss: 0.5200 - gen_loss: 0.7581 - v2v_loss_val: 1.4879 - disc_loss_val: 0.9718 - gen_loss_val: 0.1032\n",
      "Elapsed time: 9:9 mm:ss\n",
      " \n",
      "Epoch 69/200\n",
      "Batch: 46/46 - v2v_loss: 1.7284 - disc_loss: 0.9169 - gen_loss: 0.8116 - v2v_loss_val: 1.6672 - disc_loss_val: 1.2587 - gen_loss_val: 0.0817\n",
      "Elapsed time: 9:27 mm:ss\n",
      " \n",
      "Epoch 70/200\n",
      "Batch: 46/46 - v2v_loss: 1.7265 - disc_loss: 0.8449 - gen_loss: 0.8816 - v2v_loss_val: 2.3443 - disc_loss_val: 1.6834 - gen_loss_val: 0.1322\n",
      "Elapsed time: 9:10 mm:ss\n",
      " \n",
      "Epoch 71/200\n",
      "Batch: 46/46 - v2v_loss: 1.4816 - disc_loss: 0.3389 - gen_loss: 1.1426 - v2v_loss_val: 0.7849 - disc_loss_val: 0.4705 - gen_loss_val: 0.0629\n",
      "Elapsed time: 9:14 mm:ss\n",
      " \n",
      "Epoch 72/200\n",
      "Batch: 46/46 - v2v_loss: 0.9993 - disc_loss: 0.2930 - gen_loss: 0.7064 - v2v_loss_val: 0.7746 - disc_loss_val: 0.3474 - gen_loss_val: 0.0854\n",
      "Elapsed time: 9:7 mm:ss\n",
      " \n",
      "Epoch 73/200\n",
      "Batch: 46/46 - v2v_loss: 1.3068 - disc_loss: 0.3211 - gen_loss: 0.9857 - v2v_loss_val: 0.6951 - disc_loss_val: 0.3585 - gen_loss_val: 0.0673\n",
      "Elapsed time: 9:12 mm:ss\n",
      " \n",
      "Epoch 74/200\n",
      "Batch: 46/46 - v2v_loss: 0.9600 - disc_loss: 0.3231 - gen_loss: 0.6369 - v2v_loss_val: 0.7333 - disc_loss_val: 0.4333 - gen_loss_val: 0.0600\n",
      "Elapsed time: 9:21 mm:ss\n",
      " \n",
      "Epoch 75/200\n",
      "Batch: 46/46 - v2v_loss: 1.3023 - disc_loss: 0.4349 - gen_loss: 0.8675 - v2v_loss_val: 0.9792 - disc_loss_val: 0.6061 - gen_loss_val: 0.0746\n",
      "Elapsed time: 9:14 mm:ss\n",
      " \n",
      "Epoch 76/200\n",
      "Batch: 46/46 - v2v_loss: 1.0289 - disc_loss: 0.3151 - gen_loss: 0.7138 - v2v_loss_val: 0.5718 - disc_loss_val: 0.3523 - gen_loss_val: 0.0439\n",
      "Elapsed time: 9:19 mm:ss\n",
      " \n",
      "Epoch 77/200\n",
      "Batch: 46/46 - v2v_loss: 0.9741 - disc_loss: 0.3638 - gen_loss: 0.6103 - v2v_loss_val: 1.1861 - disc_loss_val: 0.4781 - gen_loss_val: 0.1416\n",
      "Elapsed time: 8:56 mm:ss\n",
      " \n",
      "Epoch 78/200\n",
      "Batch: 46/46 - v2v_loss: 0.9036 - disc_loss: 0.3751 - gen_loss: 0.5285 - v2v_loss_val: 0.8100 - disc_loss_val: 0.4932 - gen_loss_val: 0.0633\n",
      "Elapsed time: 8:58 mm:ss\n",
      " \n",
      "Epoch 79/200\n",
      "Batch: 46/46 - v2v_loss: 1.0683 - disc_loss: 0.3439 - gen_loss: 0.7243 - v2v_loss_val: 1.8442 - disc_loss_val: 0.3752 - gen_loss_val: 0.2938\n",
      "Elapsed time: 9:16 mm:ss\n",
      " \n",
      "Epoch 80/200\n",
      "Batch: 46/46 - v2v_loss: 1.2418 - disc_loss: 0.4252 - gen_loss: 0.8166 - v2v_loss_val: 1.2498 - disc_loss_val: 0.5316 - gen_loss_val: 0.1436\n",
      "Elapsed time: 9:0 mm:ss\n",
      " \n",
      "Epoch 81/200\n",
      "Batch: 46/46 - v2v_loss: 1.3589 - disc_loss: 0.3187 - gen_loss: 1.0401 - v2v_loss_val: 0.8230 - disc_loss_val: 0.3548 - gen_loss_val: 0.0936\n",
      "Elapsed time: 8:31 mm:ss\n",
      " \n",
      "Epoch 82/200\n",
      "Batch: 46/46 - v2v_loss: 1.0330 - disc_loss: 0.3133 - gen_loss: 0.7198 - v2v_loss_val: 1.0074 - disc_loss_val: 0.3840 - gen_loss_val: 0.1247\n",
      "Elapsed time: 9:8 mm:ss\n",
      " \n",
      "Epoch 83/200\n",
      "Batch: 46/46 - v2v_loss: 0.9006 - disc_loss: 0.2879 - gen_loss: 0.6126 - v2v_loss_val: 0.9493 - disc_loss_val: 0.3148 - gen_loss_val: 0.1269\n",
      "Elapsed time: 9:50 mm:ss\n",
      " \n",
      "Epoch 84/200\n",
      "Batch: 46/46 - v2v_loss: 1.2847 - disc_loss: 0.4450 - gen_loss: 0.8397 - v2v_loss_val: 1.3760 - disc_loss_val: 0.6003 - gen_loss_val: 0.1551\n",
      "Elapsed time: 9:15 mm:ss\n",
      " \n",
      "Epoch 85/200\n",
      "Batch: 46/46 - v2v_loss: 1.3542 - disc_loss: 0.3906 - gen_loss: 0.9636 - v2v_loss_val: 2.3349 - disc_loss_val: 0.4776 - gen_loss_val: 0.3715\n",
      "Elapsed time: 9:23 mm:ss\n",
      " \n",
      "Epoch 86/200\n",
      "Batch: 46/46 - v2v_loss: 1.1756 - disc_loss: 0.4549 - gen_loss: 0.7207 - v2v_loss_val: 0.9092 - disc_loss_val: 0.6883 - gen_loss_val: 0.0442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 8:58 mm:ss\n",
      " \n",
      "Epoch 87/200\n",
      "Batch: 46/46 - v2v_loss: 1.5845 - disc_loss: 0.7953 - gen_loss: 0.7892 - v2v_loss_val: 2.1456 - disc_loss_val: 1.0238 - gen_loss_val: 0.2244\n",
      "Elapsed time: 9:8 mm:ss\n",
      " \n",
      "Epoch 88/200\n",
      "Batch: 46/46 - v2v_loss: 1.0663 - disc_loss: 0.3919 - gen_loss: 0.6745 - v2v_loss_val: 0.8794 - disc_loss_val: 0.5183 - gen_loss_val: 0.0722\n",
      "Elapsed time: 9:33 mm:ss\n",
      " \n",
      "Epoch 89/200\n",
      "Batch: 46/46 - v2v_loss: 0.9098 - disc_loss: 0.3213 - gen_loss: 0.5886 - v2v_loss_val: 1.8728 - disc_loss_val: 0.3311 - gen_loss_val: 0.3083\n",
      "Elapsed time: 9:47 mm:ss\n",
      " \n",
      "Epoch 90/200\n",
      "Batch: 46/46 - v2v_loss: 0.8362 - disc_loss: 0.3643 - gen_loss: 0.4719 - v2v_loss_val: 0.4817 - disc_loss_val: 0.4774 - gen_loss_val: 0.0008\n",
      "Elapsed time: 8:59 mm:ss\n",
      " \n",
      "Validation loss decreaed from 0.5686 to 0.4817. Hence models' weights are now saved.\n",
      "Epoch 91/200\n",
      "Batch: 46/46 - v2v_loss: 1.3255 - disc_loss: 0.4457 - gen_loss: 0.8798 - v2v_loss_val: 3.3212 - disc_loss_val: 0.6055 - gen_loss_val: 0.5431\n",
      "Elapsed time: 9:4 mm:ss\n",
      " \n",
      "Epoch 92/200\n",
      "Batch: 46/46 - v2v_loss: 1.0154 - disc_loss: 0.3141 - gen_loss: 0.7013 - v2v_loss_val: 0.9139 - disc_loss_val: 0.3921 - gen_loss_val: 0.1044\n",
      "Elapsed time: 9:8 mm:ss\n",
      " \n",
      "Epoch 93/200\n",
      "Batch: 46/46 - v2v_loss: 1.2445 - disc_loss: 0.3486 - gen_loss: 0.8959 - v2v_loss_val: 0.8561 - disc_loss_val: 0.4250 - gen_loss_val: 0.0862\n",
      "Elapsed time: 8:54 mm:ss\n",
      " \n",
      "Epoch 94/200\n",
      "Batch: 46/46 - v2v_loss: 1.0113 - disc_loss: 0.4627 - gen_loss: 0.5486 - v2v_loss_val: 1.2455 - disc_loss_val: 0.6449 - gen_loss_val: 0.1201\n",
      "Elapsed time: 9:17 mm:ss\n",
      " \n",
      "Epoch 95/200\n",
      "Batch: 46/46 - v2v_loss: 1.5502 - disc_loss: 0.8234 - gen_loss: 0.7267 - v2v_loss_val: 1.1458 - disc_loss_val: 0.8255 - gen_loss_val: 0.0640\n",
      "Elapsed time: 9:3 mm:ss\n",
      " \n",
      "Epoch 96/200\n",
      "Batch: 46/46 - v2v_loss: 0.8862 - disc_loss: 0.3437 - gen_loss: 0.5425 - v2v_loss_val: 1.6246 - disc_loss_val: 0.4135 - gen_loss_val: 0.2422\n",
      "Elapsed time: 9:4 mm:ss\n",
      " \n",
      "Epoch 97/200\n",
      "Batch: 46/46 - v2v_loss: 0.8578 - disc_loss: 0.2962 - gen_loss: 0.5616 - v2v_loss_val: 0.6045 - disc_loss_val: 0.3232 - gen_loss_val: 0.0563\n",
      "Elapsed time: 9:20 mm:ss\n",
      " \n",
      "Epoch 98/200\n",
      "Batch: 46/46 - v2v_loss: 0.7981 - disc_loss: 0.2978 - gen_loss: 0.5003 - v2v_loss_val: 0.8975 - disc_loss_val: 0.3164 - gen_loss_val: 0.1162\n",
      "Elapsed time: 9:45 mm:ss\n",
      " \n",
      "Epoch 99/200\n",
      "Batch: 46/46 - v2v_loss: 0.9749 - disc_loss: 0.3134 - gen_loss: 0.6615 - v2v_loss_val: 0.8592 - disc_loss_val: 0.3726 - gen_loss_val: 0.0973\n",
      "Elapsed time: 9:5 mm:ss\n",
      " \n",
      "Epoch 100/200\n",
      "Batch: 46/46 - v2v_loss: 1.1693 - disc_loss: 0.3323 - gen_loss: 0.8369 - v2v_loss_val: 0.8028 - disc_loss_val: 0.3608 - gen_loss_val: 0.0884\n",
      "Elapsed time: 9:3 mm:ss\n",
      " \n",
      "Epoch 101/200\n",
      "Batch: 46/46 - v2v_loss: 1.1403 - disc_loss: 0.2966 - gen_loss: 0.8438 - v2v_loss_val: 3.0770 - disc_loss_val: 0.3746 - gen_loss_val: 0.5405\n",
      "Elapsed time: 8:59 mm:ss\n",
      " \n",
      "Epoch 102/200\n",
      "Batch: 46/46 - v2v_loss: 0.8417 - disc_loss: 0.3134 - gen_loss: 0.5283 - v2v_loss_val: 0.7375 - disc_loss_val: 0.3338 - gen_loss_val: 0.0807\n",
      "Elapsed time: 9:23 mm:ss\n",
      " \n",
      "Epoch 103/200\n",
      "Batch: 46/46 - v2v_loss: 1.1629 - disc_loss: 0.3717 - gen_loss: 0.7913 - v2v_loss_val: 1.0765 - disc_loss_val: 0.4706 - gen_loss_val: 0.1212\n",
      "Elapsed time: 8:48 mm:ss\n",
      " \n",
      "Epoch 104/200\n",
      "Batch: 46/46 - v2v_loss: 1.1474 - disc_loss: 0.3975 - gen_loss: 0.7499 - v2v_loss_val: 0.7799 - disc_loss_val: 0.4711 - gen_loss_val: 0.0618\n",
      "Elapsed time: 9:36 mm:ss\n",
      " \n",
      "Epoch 105/200\n",
      "Batch: 46/46 - v2v_loss: 2.2837 - disc_loss: 1.3860 - gen_loss: 0.8976 - v2v_loss_val: 4.4620 - disc_loss_val: 3.2756 - gen_loss_val: 0.2373\n",
      "Elapsed time: 9:6 mm:ss\n",
      " \n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/home/marci30/Desktop/RESULTS/cv5/pred@epoch_105.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6e4dd7f6071e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrends_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrends_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-e2f757610882>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_generator, valid_generator, nEpochs)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/pred@epoch_{}.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0mmpim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimsave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanvas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgan_losses_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mprev_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/v2v/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimsave\u001b[0;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi)\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/home/marci30/Desktop/RESULTS/cv5/pred@epoch_105.png'"
     ]
    }
   ],
   "source": [
    "trends_train, trends_valid = gan.train(train_gen, valid_gen, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
